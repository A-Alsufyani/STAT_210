table2 <- round(prop.table(table1),2)
chi_result <- chisq.test(table1)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- round(prop.table(table1, 2),2)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1, 2)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1, 1)
table2
chi_result <- chisq.test(table1)
chi_result
library(HSAUR3)
data("CHFLS")
head(CHFLS)
str(CHFLS)
df1 <- CHFLS[, c("R_age", "R_happy", "R_region")] #extract only the relevant columns
str(df1)
sum(is.na(df1))  #check if there are any mising values, is.na returns a same sized matrix with 1 if empty and 0 if not. sum sums it up
par(mar = c(8, 4, 4, 2))
boxplot(R_age ~ R_region, data = df1,
main = "Distribution of Age by Region",
xlab = "Region", ylab = "Age",
col = "lightblue",
las = 2)
mean <- tapply(df1$R_age, df1$R_region, mean)
sd <- tapply(df1$R_age, df1$R_region, sd)
median <- tapply(df1$R_age, df1$R_region, median)
IQR <- tapply(df1$R_age, df1$R_region, IQR)
head(mean)
head(sd)
head(median)
head(IQR)
q <- quantile(df1$R_age, probs = seq(0, 1, length.out = 6))
q
df1$R_a <- cut(df1$R_age,
breaks = q,
labels = c("a1", "a2", "a3", "a4", "a5"),
ordered = TRUE)
table(df1$R_a)
table1 <- table(df1$R_region, df1$R_a)
table1
mosaicplot(table1,
main = "Age Group Distribution by Region",
xlab = "Region", ylab = "Age Group (R_a)",
color = c("lightblue", "lightgreen", "pink", "orange", "violet"))
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1, 1)
table2
chi_result <- chisq.test(table1)
chi_result
chi_result$expected
chi_result$observed
#we also check that the expected values for all entries are at least 5
chi_result$expected
table3 <- table(df1$R_happy, df1$R_a)
table3
chi_age_happy <- chisq.test(table3)
chi_age_happy
chi_age_happy$expected
sum(chi_age_happy$expected < 5)
sum(chi_age_happy$expected)
sum(chi_age_happy$expected > 0)
levels(df1$R_happy)
df1$R_h <- factor(df1$R_happy,
levels = c("Very unhappy", "Not too happy", "Somewhat happy", "Very happy"),
labels = c("unhappy", "unhappy", "Somewhat happy", "Very happy"),
ordered = TRUE)
head(df1$R_h)
table(df1$R_h)
table(df1$R_happy, df1$R_h)
table4 <- table(df1$R_h, df1$R_a)
(table4 <- table(df1$R_h, df1$R_a))
(table4 <- table(df1$R_h, df1$R_a))
mosaicplot(table4,
main = "Happiness vs Age Group",
xlab = "Age Group (R_a)",
ylab = "Happiness (R_h)",
color = c("lightblue", "lightgreen", "pink"))
(table4 <- table(df1$R_h, df1$R_a))
mosaicplot(table4,
main = "Happiness vs Age Group",
xlab = "Age Group (R_a)",
ylab = "Happiness (R_h)",
color = c("lightblue", "lightgreen", "pink"))
(table4 <- table(df1$R_h, df1$R_a))
mosaicplot(table4,
main = "Happiness vs Age Group",
xlab = "Age Group (R_a)",
ylab = "Happiness (R_h)",
color = c("lightblue", "lightgreen", "pink", "orange", "violet"))
chi_happy_age <- chisq.test(table4)
chi_happy_age
chi_happy_age$expected
min(chi_happy_age$expected)
data(women)
head(Women)
head(women)
model <- lm(weight ~ height, data = women)
summary(model1)
summary(model)
plot(women$height, women$weight,
main = "Weight vs Height of American Women (30–39)",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19, col = "blue")
abline(model, col = "red", lwd = 2)
#(b) Print a summary table for the model and interpret the results. Write an equation for the model and
#interpret the coefficients. What is the R2 for this model?
summary(model)
predict(model, newdata = data.frame(height = 65), interval = "confidence")
predict(model, newdata = data.frame(height = 65), interval = "confidence", level = 0.98)
#(b) Print a summary table for the model and interpret the results. Write an equation for the model and
#interpret the coefficients. What is the R2 for this model?
summary(model)
predict(model, newdata = data.frame(height = 65), interval = "confidence", level = 0.98)
par(mfrow = c(2, 2))
plot(model)
#we futher test for these assumptiopns
shapiro.test(residuals(model))
library(car)
ncvTest(model)
residualPlots(model)
model2 <- lm(weight ~ height + I(height^2), data = women)
summary(model2)
plot(height, weight, data = women,
main = "Weight vs Height with Linear and Quadratic Fits",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19,            # solid circles
col = "darkblue")
head(women)
plot(women$height, women$weight,
main = "Weight vs Height with Linear and Quadratic Fits",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19,            # solid circles
col = "darkblue")
par(mfrow = c(1, 1))
plot(women$height, women$weight,
main = "Weight vs Height with Linear and Quadratic Fits",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19,            # solid circles
col = "darkblue")
abline(model, col = "red", lwd = 2)
x_vals <- seq(min(women$height), max(women$height), length.out = 200)
y_quad <- predict(model2, newdata = data.frame(height = x_vals))
lines(x_vals, y_quad, col = "darkgreen", lwd = 2)
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
par(mfrow = c(1, 1))
plot(women$height, women$weight,
main = "Weight vs Height with Linear and Quadratic Fits",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19,            # solid circles
col = "darkblue")
abline(model, col = "red", lwd = 2)
x_vals <- seq(min(women$height), max(women$height), length.out = 200)
y_quad <- predict(model2, newdata = data.frame(height = x_vals))
lines(x_vals, y_quad, col = "darkgreen", lwd = 2)
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
predict(model2,
newdata = data.frame(height = 65),
interval = "confidence",
level = 0.98)
setwd("C:/Users/ksa4e/OneDrive/Desktop/KAUST/STAT_210/HW7")
data <- read.csv("25Fhw7Q1.csv")
head(data)
lot(data$varx, data$vary,
xlab = "varx",
ylab = "vary",
main = "Scatterplot of vary vs varx")
plot(data$varx, data$vary,
xlab = "varx",
ylab = "vary",
main = "Scatterplot of vary vs varx")
model <- lm(vary ~ varx, data = data)
abline(model, col = "red", lwd = 2)
summary(model)
par(mfrow = c(2, 2))   # 4 diagnostic plots
plot(model)
shapiro.test(residuals(model))
par(mfrow = c(2, 2))   # 4 diagnostic plots
plot(model)
shapiro.test(residuals(model))
leveneTest(mod1)
leveneTest(model)
#shapiro test of normality, with p-value of 2.34e-07 < 0.02, we reject null hypothesis and we say the data is not normally distributed.
library(car)
leveneTest(model)
data <- read.csv("25Fhw7Q1.csv")
head(data)
data <- read.csv("25Fhw7Q1.csv")
head(data)
# plot the data
plot(data$varx, data$vary,
xlab = "varx",
ylab = "vary",
main = "Scatterplot of vary vs varx")
#fit a  simple linear regressio model
model <- lm(vary ~ varx, data = data)
abline(model, col = "red", lwd = 2)
summary(model)
par(mfrow = c(2, 2))   # 4 diagnostic plots
plot(model)
shapiro.test(residuals(model))
#shapiro test of normality, with p-value of 2.34e-07 < 0.02, we reject null hypothesis and we say the data is not normally distributed.
library(car)
leveneTest(model)
View(data)
leveneTest(residuals(model))
ncvTest(model)
predict(model, data.frame(varx = 2.5), interval = 'c', level = 0.98)
library(mass)
library(MASS)
boxcox(model)
par(mfrow = c(1, 1))
boxcox(model)
data$log_vary <- log(data$vary)
data$log_vary <- log(data$vary)
model_log <- lm(log_vary ~ varx, data = data)
plot(data$varx, data$log_vary,
xlab = "varx",
ylab = "log_vary",
main = "Scatterplot of log_vary vs varx")
abline(model_og, col = "red", lwd = 2)
model_log <- lm(log_vary ~ varx, data = data)
abline(model_;og, col = "red", lwd = 2)
abline(model_log, col = "red", lwd = 2)
model_log
summary(model_log)
par(mfrow = c(2,2))
plot(model_log)
shapiro.test(residuals(model_log))
ncvTest(model)
predict(model_log, data.frame(varx = 2.5), interval = "c", level = 0.98)
log_prediction <- predict(model_log, data.frame(varx = 2.5), interval = "c", level = 0.98)
log_prediction <- predict(model_log, data.frame(varx = 2.5), interval = "c", level = 0.98)
(log_prediction <- predict(model_log, data.frame(varx = 2.5), interval = "c", level = 0.98))
(original_prediction <- exp(log_prediction))
predict(model, data.frame(varx = 2.5), interval = 'c', level = 0.98)
plot(vary ~ varx, data = data, pch = 16,
xlab = "varx", ylab = "vary",
main = "Scatterplot of vary vs varx")
par(mfrow = c(1,1))
plot(vary ~ varx, data = data, pch = 16,
xlab = "varx", ylab = "vary",
main = "Scatterplot of vary vs varx")
abline(model, col = "blue", lwd = 2)
# plot the data
plot(data$varx, data$vary,
xlab = "varx",
ylab = "vary",
main = "Scatterplot of vary vs varx")
plot(vary ~ varx, data = data, pch = 16,
xlab = "varx", ylab = "vary",
main = "Scatterplot of vary vs varx")
abline(model, col = "blue", lwd = 2)
plot(vary ~ varx, data = data,
xlab = "varx", ylab = "vary",
main = "Scatterplot of vary vs varx")
abline(model, col = "blue", lwd = 2)
curve(exp(coef(model_log)[1] + coef(model_log)[2] * x),
add = TRUE, col = "red", lwd = 2)
par(mfrow = c(1,1))
plot(vary ~ varx, data = data,
xlab = "varx", ylab = "vary",
main = "Scatterplot of vary vs varx")
abline(model, col = "blue", lwd = 2)
curve(exp(model_log) * x,
add = TRUE, col = "red", lwd = 2))
curve(exp(model_log) * x,
add = TRUE, col = "red", lwd = 2)
curve(exp(model_log)[1] * x,
add = TRUE, col = "red", lwd = 2)
curve(exp(coef(model_log)[1] + coef(model_log)[2] * x),
add = TRUE, col = "red", lwd = 2)
model_log <- lm(log_vary ~ varx, data = data)
(model_log <- lm(log_vary ~ varx, data = data))
curve(exp(coef(model_log)[1] + coef(model_log)[2] * x),
add = TRUE, col = "red", lwd = 2)
legend("topleft",
legend = c("Original linear model", "Transformed model"),
col = c("blue", "red"),
lwd = 2)
data2 <- read.csv("25Fhw7Q2.csv")
str(data2)
plot(w ~ t, data = data2, pch = 16,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
plot(w ~ t, data = data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
model2 <- lm(w ~ t, data = data2)
abline(model2, col = "red", lwd = 2)
summary(model2)
summary(model2)
par(mfrow = c(2,2))
plot(model2)
plot(w ~ t, data = data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
par(mfrow = c(1,1))
plot(w ~ t, data = data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
abline(model2, col = "red", lwd = 2)
par(mfrow = c(2,2))
plot(model2)
#we can probably identify these points to be the point at t = 50, and the two points at t aprproximately = 35 and 36 with w values of less than -5.
data[15,]
#we can probably identify these points to be the point at t = 50, and the two points at t aprproximately = 35 and 36 with w values of less than -5.
data2[15,]
data2[12,]
plot(w ~ t, data = data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
model2 <- lm(w ~ t, data = data2)
par(mfrow = c(1,1))
plot(w ~ t, data = data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
model2 <- lm(w ~ t, data = data2)
abline(model2, col = "red", lwd = 2)
,
,
par(mfrow = c(2,2))
plot(model2)
par(mfrow = c(1,1))
data2[8, ]
data2[10, ]
data3 <- data2[-c(8,10,15),]
clean_data2 <- data2[-c(8,10,15),]
plot(w ~ t, data = clean_data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
clean_data2 <- data2[-c(8,10,15),]
plot(w ~ t, data = clean_data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
clean_model2 <- lm(w ~ t, data = clean_data2)
abline(clean_model2, col = "red", lwd = 2)
plot(w ~ t, data = data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
clean_model2 <- lm(w ~ t, data = clean_data2)
abline(clean_model2, col = "red", lwd = 2)
abline(clean_model2, col = "blue", lwd = 2)
abline(model2, col = "red", lwd = 2)
summary(clean_model2)
plot(w ~ t, data = clean_data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
clean_model2 <- lm(w ~ t, data = clean_data2)
abline(clean_model2, col = "blue", lwd = 2)
abline(model2, col = "red", lwd = 2)
shapiro.test(residuals(model2))
ncvTest(model2)
par(mfrow = c(2,2))
plot(clean_model2)
par(mfrow = c(1,1))
data2 <- read.csv("25Fhw7Q2.csv")
str(data2)
plot(w ~ t, data = data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
model2 <- lm(w ~ t, data = data2)
abline(model2, col = "red", lwd = 2)
summary(model2)
par(mfrow = c(2,2))
plot(model2)
data2[12, ]
clean_data2 <- data2[-c(8,10,15, 12),]
plot(w ~ t, data = clean_data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
clean_model2 <- lm(w ~ t, data = clean_data2)
par(mfrow = c(1,1))
clean_data2 <- data2[-c(8,10,15, 12),]
plot(w ~ t, data = clean_data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
clean_model2 <- lm(w ~ t, data = clean_data2)
abline(clean_model2, col = "blue", lwd = 2)
abline(model2, col = "red", lwd = 2)
summary(clean_model2)
par(mfrow = c(2,2))
plot(clean_model2)
par(mfrow = c(1,1))
shapiro.test(residuals(model2))
ncvTest(model2)
par(mfrow = c(2,2))
plot(model2)
par(mfrow = c(1,1))
shapiro.test(residuals(model2))
ncvTest(model2)
#we can probably identify these points to be the point at t = 50, and the two points at t aprproximately = 35 and 36 with w values of less than -5.
#we can see them more clearly reading directly from the data
data2[15,]
data2[10, ]
clean_data2 <- data2[-c(8,10,15),]
plot(w ~ t, data = clean_data2,
xlab = "t", ylab = "w",
main = "Scatterplot of w vs t")
clean_model2 <- lm(w ~ t, data = clean_data2)
abline(clean_model2, col = "blue", lwd = 2)
abline(model2, col = "red", lwd = 2)
summary(clean_model2)
par(mfrow = c(2,2))
plot(clean_model2)
par(mfrow = c(1,1))
shapiro.test(residuals(model2))
ncvTest(model2)
shapiro.test(residuals(model2))
ncvTest(model2)
shapiro.test(residuals(clean_model2))
ncvTest(clean_model2)
ncvTest(clean_model2)
(invXtX <- summary(clean_model2)$cov.unscaled)
summary(clean_model2)$sigma
summary(model2)$sigmaˆ2
summary(clean_model2)$sigmaˆ2
(std <-summary(clean_model2)$sigma) # standard deviation
(std^2)
vcov(clean_model2) # estimated covariance
#which is also equivalent to
((std^2) * invXtX)
#which should also be equivalent to
((std^2) * invXtX)
confint(clean_model2, level = 0.99)
confint(model2, level = 0.99)
predict(model2,
newdata = data.frame(t = 45),
interval = "confidence",
level = 0.99)
predict(clean_model2,
newdata = data.frame(t = 45),
interval = "confidence",
level = 0.99)

table2 <- prop.table(tab1, margin = 1)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1, margin = 1)
table2
chi_result <- chisq.test(tab1)
chi_result <- chisq.test(table1)
chi_result
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- round(prop.table(table1),2)
chi_result <- chisq.test(table1)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- round(prop.table(table1, 2),2)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1, 2)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1)
table2
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1, 1)
table2
chi_result <- chisq.test(table1)
chi_result
library(HSAUR3)
data("CHFLS")
head(CHFLS)
str(CHFLS)
df1 <- CHFLS[, c("R_age", "R_happy", "R_region")] #extract only the relevant columns
str(df1)
sum(is.na(df1))  #check if there are any mising values, is.na returns a same sized matrix with 1 if empty and 0 if not. sum sums it up
par(mar = c(8, 4, 4, 2))
boxplot(R_age ~ R_region, data = df1,
main = "Distribution of Age by Region",
xlab = "Region", ylab = "Age",
col = "lightblue",
las = 2)
mean <- tapply(df1$R_age, df1$R_region, mean)
sd <- tapply(df1$R_age, df1$R_region, sd)
median <- tapply(df1$R_age, df1$R_region, median)
IQR <- tapply(df1$R_age, df1$R_region, IQR)
head(mean)
head(sd)
head(median)
head(IQR)
q <- quantile(df1$R_age, probs = seq(0, 1, length.out = 6))
q
df1$R_a <- cut(df1$R_age,
breaks = q,
labels = c("a1", "a2", "a3", "a4", "a5"),
ordered = TRUE)
table(df1$R_a)
table1 <- table(df1$R_region, df1$R_a)
table1
mosaicplot(table1,
main = "Age Group Distribution by Region",
xlab = "Region", ylab = "Age Group (R_a)",
color = c("lightblue", "lightgreen", "pink", "orange", "violet"))
#from the mosaic plot we see that some regions have much less entires (width of the rectangles)
#also we see that the each region has a different age distribution, for example coastal south has about 50% of its population on age groups a1 and a2.
#while coastal east has about the same percentage but lying in groups a4 and a5
table2 <- prop.table(table1, 1)
table2
chi_result <- chisq.test(table1)
chi_result
chi_result$expected
chi_result$observed
#we also check that the expected values for all entries are at least 5
chi_result$expected
table3 <- table(df1$R_happy, df1$R_a)
table3
chi_age_happy <- chisq.test(table3)
chi_age_happy
chi_age_happy$expected
sum(chi_age_happy$expected < 5)
sum(chi_age_happy$expected)
sum(chi_age_happy$expected > 0)
levels(df1$R_happy)
df1$R_h <- factor(df1$R_happy,
levels = c("Very unhappy", "Not too happy", "Somewhat happy", "Very happy"),
labels = c("unhappy", "unhappy", "Somewhat happy", "Very happy"),
ordered = TRUE)
head(df1$R_h)
table(df1$R_h)
table(df1$R_happy, df1$R_h)
table4 <- table(df1$R_h, df1$R_a)
(table4 <- table(df1$R_h, df1$R_a))
(table4 <- table(df1$R_h, df1$R_a))
mosaicplot(table4,
main = "Happiness vs Age Group",
xlab = "Age Group (R_a)",
ylab = "Happiness (R_h)",
color = c("lightblue", "lightgreen", "pink"))
(table4 <- table(df1$R_h, df1$R_a))
mosaicplot(table4,
main = "Happiness vs Age Group",
xlab = "Age Group (R_a)",
ylab = "Happiness (R_h)",
color = c("lightblue", "lightgreen", "pink"))
(table4 <- table(df1$R_h, df1$R_a))
mosaicplot(table4,
main = "Happiness vs Age Group",
xlab = "Age Group (R_a)",
ylab = "Happiness (R_h)",
color = c("lightblue", "lightgreen", "pink", "orange", "violet"))
chi_happy_age <- chisq.test(table4)
chi_happy_age
chi_happy_age$expected
min(chi_happy_age$expected)
data(women)
head(Women)
head(women)
model <- lm(weight ~ height, data = women)
summary(model1)
summary(model)
plot(women$height, women$weight,
main = "Weight vs Height of American Women (30â€“39)",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19, col = "blue")
abline(model, col = "red", lwd = 2)
#(b) Print a summary table for the model and interpret the results. Write an equation for the model and
#interpret the coefficients. What is the R2 for this model?
summary(model)
predict(model, newdata = data.frame(height = 65), interval = "confidence")
predict(model, newdata = data.frame(height = 65), interval = "confidence", level = 0.98)
#(b) Print a summary table for the model and interpret the results. Write an equation for the model and
#interpret the coefficients. What is the R2 for this model?
summary(model)
predict(model, newdata = data.frame(height = 65), interval = "confidence", level = 0.98)
par(mfrow = c(2, 2))
plot(model)
#we futher test for these assumptiopns
shapiro.test(residuals(model))
library(car)
ncvTest(model)
residualPlots(model)
model2 <- lm(weight ~ height + I(height^2), data = women)
summary(model2)
plot(height, weight, data = women,
main = "Weight vs Height with Linear and Quadratic Fits",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19,            # solid circles
col = "darkblue")
head(women)
plot(women$height, women$weight,
main = "Weight vs Height with Linear and Quadratic Fits",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19,            # solid circles
col = "darkblue")
par(mfrow = c(1, 1))
plot(women$height, women$weight,
main = "Weight vs Height with Linear and Quadratic Fits",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19,            # solid circles
col = "darkblue")
abline(model, col = "red", lwd = 2)
x_vals <- seq(min(women$height), max(women$height), length.out = 200)
y_quad <- predict(model2, newdata = data.frame(height = x_vals))
lines(x_vals, y_quad, col = "darkgreen", lwd = 2)
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
par(mfrow = c(1, 1))
plot(women$height, women$weight,
main = "Weight vs Height with Linear and Quadratic Fits",
xlab = "Height (inches)",
ylab = "Weight (pounds)",
pch = 19,            # solid circles
col = "darkblue")
abline(model, col = "red", lwd = 2)
x_vals <- seq(min(women$height), max(women$height), length.out = 200)
y_quad <- predict(model2, newdata = data.frame(height = x_vals))
lines(x_vals, y_quad, col = "darkgreen", lwd = 2)
legend("topleft",
legend = c("Data", "Linear fit", "Quadratic fit"),
col = c("darkblue", "red", "darkgreen"),
pch = c(19, NA, NA),
lty = c(NA, 1, 1),
lwd = c(NA, 2, 2),
bty = "n")
predict(model2,
newdata = data.frame(height = 65),
interval = "confidence",
level = 0.98)
setwd("C:/Users/ksa4e/OneDrive/Desktop/KAUST/STAT_210/HW8")
data <- read.csv("HW825FQ1.csv")
head(data)
str(data)
summary(data)
#summary(data)
library(car)
scatterplotMatrix(~ Y + X1 + X2 + X3 + X4 + X5 + X6 + X7, data = data)
sum(is.na(data))
scatterplotMatrix(~ Y + X1 + X2 + X3 + X4 + X5 + X6 + X7, data = data,
main = "Scatterplot of All variables")
library(corrplot)
install.packages("corrplot")
library(corrplot)
corrplot.mixed(cor_mat,
upper = "color",    # heatmap colors on top triangle
lower = "number",   # actual numeric correlations on bottom
tl.col = "black",
number.cex = 0.8,
main = "Mixed Correlation Matrix")
scatterplotMatrix(data,
main = "Scatterplot of All variables")
scatterplotMatrix(data)
corrplot.mixed(cor_mat,
upper = "color",    # heatmap colors on top triangle
lower = "number",   # actual numeric correlations on bottom
tl.col = "black",
number.cex = 0.8,
main = "Mixed Correlation Matrix")
q1_data <- read.csv("HW825FQ1.csv")
#head(data)
str(q1_data)
library(car)
scatterplotMatrix(q1_data)
library(corrplot)
corrplot.mixed(cor_mat,
upper = "color",    # heatmap colors on top triangle
lower = "number",   # actual numeric correlations on bottom
tl.col = "black",
number.cex = 0.8,
main = "Mixed Correlation Matrix")
cor_1 <- cor(q1_data)
corrplot.mixed(cor_1,
upper = "color",    # heatmap colors on top triangle
lower = "number",   # actual numeric correlations on bottom
tl.col = "black",
number.cex = 0.8,
main = "Mixed Correlation Matrix")
corrplot.mixed(cor_1)
install.packages("GGally")
library(GGally)
ggcorr(cor_1)
scatterplotMatrix(q1_data)
library(corrplot)
library(corrplot)
cor_1 <- cor(q1_data)
corrplot.mixed(cor_1)
scatterplotMatrix(q1_data)
corrplot.mixed(cor_1)
full_model <- lm(Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7, data = q1_data)
summary(full_model)
vif(mod1)
vif(full_model)
# x6 is the only one below a threshold of 2, we drop the highest value which is x3.
mod1 <- update(full_model, .~. - x3)
vif(mod1)
# x6 is the only one below a threshold of 2, we drop the highest value which is x3.
mod1 <- update(full_model, .~. - X33)
# x6 is the only one below a threshold of 2, we drop the highest value which is x3.
mod1 <- update(full_model, .~. - X3)
vif(mod1)
vif(full_model)
# x6 is the only one below a threshold of 2, we drop the highest value which is x3.
mod1 <- update(full_model, .~. - X3)
vif(mod1)
#again for x1
mod2 <- update(mod1, .~. - X1)
vif(mod2)
#again for x5
mod3 <- update(mod2, .~. - X5)
vif(mod3)
summary(mod3)
#we drop the highest P-value (most insignficant variable) which is X6.
drop1(mod3)
#we drop the highest P-value (most insignficant variable) which is X6.
drop1(mod3, test = "F")
#we drop the highest P-value (most insignficant variable) which is X6.
drop1(mod3)
#we drop the highest P-value (most insignficant variable) which is X6.
drop1(mod3, test = "F")
#with alpha_critical = 0.1, we start using backward selection procedure.
summary(mod3)
#we drop the highest P-value (most insignificant variable) which is X6.
mod4 <- update(mod3, .~. - X6)
#and we repeat
drop1(mod4, test = "F")
#with alpha_critical = 0.1, we start using backward selection procedure.
drop1(mod3, test = "F")
#and we repeat
drop1(mod4, test = "F")
library(MASS)
aic_model <- stepAIC(full_model)
aic_model <- stepAIC(full_model)
clr
clr()
cls
aic_model <- stepAIC(full_model)
summary(aic_model)
#since all values are > alpha_critical, we found our minimal adequate model. using variables X2, X4, X7 to predict Y
summary(mod4)
summary(aic_model)
#since all values are > alpha_critical, we found our minimal adequate model. using variables X2, X4, X7 to predict Y
summary(mod4)
summary(aic_model)
#since all values are > alpha_critical, we found our minimal adequate model. using variables X2, X4, X7 to predict Y
summary(mod4)
install.packages("leaps")
library(leaps)
subsets <- regsubsets(q1_data)
subsets <- regsubsets(full_model)
q1_data[,-1]
subsets <- regsubsets(q1_data[ , -1])
subsets <- regsubsets(q1_data[ , -1], q1_data[1])
subsets <- regsubsets(q1_data[ , -1], q1_data[,1])
summary(subsets)
summary(subsets)$adjr2
summary(subsets)$adjr2
summary(aic_model)
#since all values are > alpha_critical, we found our minimal adequate model. using variables X2, X4, X7 to predict Y
summary(mod4)
vif(best_adjR2_model) # check for multicollinearity
best_adjR2_model <- lm(Y ~ X1 + X4 + X7, data = q1_data) #fit the maximum r^2 model
vif(best_adjR2_model) # check for multicollinearity
plot(mod4)
par(mfrow = c(2, 2))
plot(mod4)
par(mfrow = c(1, 1))
shapiro.test(residuals(mod4))
ncvTest(mod4)
#since all values are > alpha_critical, we found our minimal adequate model. using variables X2, X4, X7 to predict Y
summary(mod4)
predict_data <- data.frame(X2 = 9.6, X4 = 9.2, X7 = -0.8)
predict_data <- data.frame(X2 = 9.6, X4 = 9.2, X7 = -0.8)
predict(mod4, newdata = predict_data, interval = "c", level = 0.98)
q2_data <- read.csv("HW825FQ2.csv")
#head(data)
str(q2_data)
vif(full_model)
# x6 is the only one below a threshold of 2, we drop the highest value which is x3.
mod1 <- update(full_model, .~. - X3)
vif(mod1)
#again for x1
mod2 <- update(mod1, .~. - X1)
vif(mod2)
vif(full_model)
# x6 is the only one below a threshold of 2, we drop the highest value which is x3.
mod1 <- update(full_model, .~. - X3)
vif(mod1)
#again for x1
mod2 <- update(mod1, .~. - X1)
vif(mod2)
#again for x5
mod3 <- update(mod2, .~. - X5)
vif(mod3)
#with alpha_critical = 0.1, we start using backward selection procedure.
drop1(mod3, test = "F")
q2_data <- read.csv("HW825FQ2.csv")
#head(data)
str(q2_data)
q2_data$member <- as.factor(q2_data$member)
str(q2_data)
#head(data)
str(q1_data)
str(q2_data)
mod_a <- lm(duration ~ age, data = q2_data)
summary(mod_a)
plot(q2_data$age, q2_data$duration,
xlab = "Age",
ylab = "Duration",
main = "Scatterplot of Duration vs Age")
abline(model_a, col = "red", lwd = 2)
abline(mod_a, col = "red", lwd = 2)
par(mfrow = c(2, 2))
plot(mod_a)
par(mfrow = c(1, 1))
shapiro.test(residuals(mod_a))
ncvTest(mod_a)
predict(mod_a, newdata = data.frame(age = 45), interval = "c", level = "0.98")
predict(mod_a, newdata = data.frame(age = 45), interval = "c", level = 0.98)
plot(q2_data$age, q2_data$duration,
col = c("blue", "red")[q2_data$member]
xlab = "Age",
plot(q2_data$age, q2_data$duration,
col = c("blue", "red")[q2_data$member],
xlab = "Age",
ylab = "Duration",
main = "Scatterplot of Duration vs Age")
mod_b <- lm(duration ~ age * member)
mod_b <- lm(duration ~ age * member, data = q2_data)
anova(mod_b)
#looking at the P values of the predictors, we see that age, member, and their interactions are signficant for predicting duration.
#therefore we don't drop any variable and take this to be the minimal adequate fitting model.
summary(mod_b)
legend("topleft",
legend = c("Member", "Non-Member"),
col = c("blue", "red"),
lwd = 2)
plot(q2_data$age, q2_data$duration,
col = c("blue", "red")[-q2_data$member],
xlab = "Age",
ylab = "Duration",
main = "Scatterplot of Duration vs Age")
plot(q2_data$age, q2_data$duration,
col = c("blue", "red")[q2_data$member],
xlab = "Age",
ylab = "Duration",
main = "Scatterplot of Duration vs Age")
plot(q2_data$age, q2_data$duration,
col = c("blue", "red")[q2_data$member],
xlab = "Age",
ylab = "Duration",
main = "Scatterplot of Duration vs Age")
legend("topleft",
legend = c("Non-Member", "Member"),
col = c("blue", "red"),
lwd = 2)
#head(data)
str(q2_data)
plot(q2_data$age, q2_data$duration,
col = c("blue", "red")[q2_data$member],
xlab = "Age",
ylab = "Duration",
main = "Scatterplot of Duration vs Age")
legend("topleft",
legend = c("Non-Member", "Member"),
col = c("blue", "red"),
lwd = 2)
abline(a = coef(mod_b)[1], b = coef(mod_b)[2], col = "blue", lwd = 2)
abline(a = coef(mod_b)[1] + coef(mod_b)[3],
b = coef(mod_b)[2] + coef(mod_b)[4],
col = "red", lwd = 2)
summary(mod_b)
plot(mod_b)
par(mfrow = c(2, 2))
plot(mod_b)
par(mfrow = c(1, 1))
shapiro.test(residuals(mod_b))
ncvTest(mod_b)
predict_non_member <- predict(mod_b, newdata = data.frame(age = 45, member = 0), interval = "c", level = 0.98)
predict(mod_b, newdata = data.frame(age = 45, member = 0), interval = "c", level = 0.98)
predict(mod_b, newdata = data.frame(age = 45, member = "0"), interval = "c", level = 0.98)
predict_npn <- predict(mod_b, newdata = data.frame(age = 45, member = "0"), interval = "c", level = 0.98)
predict_non <- predict(mod_b, newdata = data.frame(age = 45, member = "0"), interval = "c", level = 0.98)
predict_non
predict_member <- predict(mod_b, newdata = data.frame(age = 45, member = "1"), interval = "c", level = 0.98)
predict_non
(predict_member <- predict(mod_b, newdata = data.frame(age = 45, member = "1"), interval = "c", level = 0.98))
legend("topleft",
legend = c("Non-Member", "Member"),
col = c("blue", "red"),
lwd = 2)
